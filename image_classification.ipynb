{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0411d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from d2l import torch as d2l\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.autograd import Function\n",
    "from torch.autograd import Variable as V\n",
    "device = d2l.try_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1eb60964",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vfosgd_pf\n",
    "class VFOSGD_PF(Optimizer):\n",
    "\n",
    "\n",
    "    def __init__(self, params, lr=1e-1,r=0.9):  #r on behalf of fractional order \n",
    "        if not 0.0 <= lr:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "            \n",
    "        if not -2.0 <= r:\n",
    "            raise ValueError(\"Invalid r value: {}\".format(r))\n",
    "            \n",
    "        defaults = dict(lr=lr,r=r)\n",
    "        super(VFOSGD_PF, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(VFOSGD_PF, self).__setstate__(state)\n",
    "        \n",
    "    \n",
    "    def step(self, closure=None):\n",
    "        eps=1e-8\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('VFOSGD_PF does not support sparse gradients')\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                # State initialization\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                 \n",
    "                fractional_order_grad_other = grad.clone()\n",
    "                \n",
    "                state['step'] += 1\n",
    "                \n",
    "                r = group['r']\n",
    "                \n",
    "                step_size = group['lr']\n",
    "                \n",
    "                x = p.data\n",
    "                #vfogd_pf\n",
    "                y1 = torch.where(x <= 0, torch.tensor([eps]).to(device), x.to(device))\n",
    "                y2 = torch.where(x > 0, torch.tensor([eps]).to(device), torch.tensor([1.0]).to(device))\n",
    "                \n",
    "                y1 = fractional_order_grad_other*y1**(1-r)/math.gamma(2-r)\n",
    "                y2 = fractional_order_grad_other*y2\n",
    "                \n",
    "                g = y1 + y2\n",
    "                \n",
    "                p.data.add_(-step_size, g)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "\n",
    "#vfoAdam_pf\n",
    "class VFOAdam_PF(Optimizer):\n",
    "\n",
    "\n",
    "    def __init__(self, params, lr=1e-1, betas=(0.9, 0.999), eps=1e-8,r=0.9):  #r on behalf of fractional order \n",
    "        if not 0.0 <= lr:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "         \n",
    "        if not 0.0 <= eps:\n",
    "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
    "            \n",
    "        if not 0.0 <= betas[0] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
    "            \n",
    "        if not 0.0 <= betas[1] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
    "            \n",
    "        if not -2.0 <= r:\n",
    "            raise ValueError(\"Invalid r value: {}\".format(r))\n",
    "            \n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps,r=r)\n",
    "        super(VFOAdam_PF, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(VFOAdam_PF, self).__setstate__(state)\n",
    "        \n",
    "    \n",
    "    def step(self, closure=None):\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('VFOAdam_PF does not support sparse gradients')\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                # State initialization\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    #initialize first moment and second moment\n",
    "                    state['m'] = 0;state['v'] = 0\n",
    "                \n",
    "                fractional_order_grad_other = grad.clone()\n",
    "                    \n",
    "                state['step'] += 1\n",
    "                \n",
    "                r = group['r']\n",
    "                \n",
    "                step_size = group['lr']\n",
    "                \n",
    "                beta1, beta2 = group['betas']\n",
    "                \n",
    "                x = p.data\n",
    "                #vfogd_pf\n",
    "                y1 = torch.where(x <= 0, torch.tensor([group['eps']]).to(device), x.to(device))\n",
    "                y2 = torch.where(x > 0, torch.tensor([group['eps']]).to(device), torch.tensor([1.0]).to(device))\n",
    "                \n",
    "                y1 = fractional_order_grad_other*y1**(1-r)/math.gamma(2-r)\n",
    "                y2 = fractional_order_grad_other*y2\n",
    "                \n",
    "                g = y1 + y2                \n",
    "                \n",
    "                state['m'] = torch.add(beta1*state['m'],(1-beta1)*g)\n",
    "                \n",
    "                state['v'] = torch.add(beta2*state['v'],(1-beta2)*g**2)\n",
    "                \n",
    "                m = state['m']/(1 - beta1**state['step'])\n",
    "                \n",
    "                v = state['v']/(1 - beta2**state['step'])\n",
    "                \n",
    "                p.data.add_(-step_size, m/(torch.sqrt(v) + group['eps']))\n",
    "                \n",
    "        return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5e489e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入Fashion-MNIST数据集\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aee47144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c17cf379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 0.711\n",
      "Accuracy of the network on the test images: 80.24 %\n",
      "[2] loss: 0.447\n",
      "Accuracy of the network on the test images: 83.70 %\n",
      "[3] loss: 0.387\n",
      "Accuracy of the network on the test images: 85.00 %\n",
      "[4] loss: 0.351\n",
      "Accuracy of the network on the test images: 86.42 %\n",
      "[5] loss: 0.326\n",
      "Accuracy of the network on the test images: 87.14 %\n",
      "[6] loss: 0.307\n",
      "Accuracy of the network on the test images: 87.05 %\n",
      "[7] loss: 0.294\n",
      "Accuracy of the network on the test images: 87.98 %\n",
      "[8] loss: 0.281\n",
      "Accuracy of the network on the test images: 88.19 %\n",
      "[9] loss: 0.269\n",
      "Accuracy of the network on the test images: 88.56 %\n",
      "[10] loss: 0.258\n",
      "Accuracy of the network on the test images: 88.15 %\n",
      "[11] loss: 0.252\n",
      "Accuracy of the network on the test images: 88.59 %\n",
      "[12] loss: 0.242\n",
      "Accuracy of the network on the test images: 89.11 %\n",
      "[13] loss: 0.235\n",
      "Accuracy of the network on the test images: 88.88 %\n",
      "[14] loss: 0.227\n",
      "Accuracy of the network on the test images: 88.77 %\n",
      "[15] loss: 0.219\n",
      "Accuracy of the network on the test images: 88.15 %\n",
      "[16] loss: 0.213\n",
      "Accuracy of the network on the test images: 88.29 %\n",
      "[17] loss: 0.207\n",
      "Accuracy of the network on the test images: 89.06 %\n",
      "[18] loss: 0.200\n",
      "Accuracy of the network on the test images: 88.95 %\n",
      "[19] loss: 0.194\n",
      "Accuracy of the network on the test images: 89.20 %\n",
      "[20] loss: 0.188\n",
      "Accuracy of the network on the test images: 88.84 %\n",
      "[21] loss: 0.183\n",
      "Accuracy of the network on the test images: 88.75 %\n",
      "[22] loss: 0.177\n",
      "Accuracy of the network on the test images: 88.63 %\n",
      "[23] loss: 0.173\n",
      "Accuracy of the network on the test images: 89.28 %\n",
      "[24] loss: 0.168\n",
      "Accuracy of the network on the test images: 89.55 %\n",
      "[25] loss: 0.163\n",
      "Accuracy of the network on the test images: 89.02 %\n",
      "[26] loss: 0.159\n",
      "Accuracy of the network on the test images: 89.21 %\n",
      "[27] loss: 0.154\n",
      "Accuracy of the network on the test images: 89.57 %\n",
      "[28] loss: 0.149\n",
      "Accuracy of the network on the test images: 89.50 %\n",
      "[29] loss: 0.145\n",
      "Accuracy of the network on the test images: 88.97 %\n",
      "[30] loss: 0.140\n",
      "Accuracy of the network on the test images: 89.07 %\n",
      "[31] loss: 0.137\n",
      "Accuracy of the network on the test images: 88.30 %\n",
      "[32] loss: 0.133\n",
      "Accuracy of the network on the test images: 89.28 %\n",
      "[33] loss: 0.129\n",
      "Accuracy of the network on the test images: 89.31 %\n",
      "[34] loss: 0.126\n",
      "Accuracy of the network on the test images: 89.28 %\n",
      "[35] loss: 0.123\n",
      "Accuracy of the network on the test images: 89.21 %\n",
      "[36] loss: 0.118\n",
      "Accuracy of the network on the test images: 89.04 %\n",
      "[37] loss: 0.116\n",
      "Accuracy of the network on the test images: 88.90 %\n",
      "[38] loss: 0.113\n",
      "Accuracy of the network on the test images: 89.15 %\n",
      "[39] loss: 0.110\n",
      "Accuracy of the network on the test images: 89.19 %\n",
      "[40] loss: 0.107\n",
      "Accuracy of the network on the test images: 88.88 %\n",
      "[41] loss: 0.102\n",
      "Accuracy of the network on the test images: 88.76 %\n",
      "[42] loss: 0.100\n",
      "Accuracy of the network on the test images: 88.71 %\n",
      "[43] loss: 0.097\n",
      "Accuracy of the network on the test images: 88.62 %\n",
      "[44] loss: 0.098\n",
      "Accuracy of the network on the test images: 89.08 %\n",
      "[45] loss: 0.093\n",
      "Accuracy of the network on the test images: 88.55 %\n",
      "[46] loss: 0.091\n",
      "Accuracy of the network on the test images: 88.80 %\n",
      "[47] loss: 0.087\n",
      "Accuracy of the network on the test images: 88.97 %\n",
      "[48] loss: 0.091\n",
      "Accuracy of the network on the test images: 89.17 %\n",
      "[49] loss: 0.083\n",
      "Accuracy of the network on the test images: 88.32 %\n",
      "[50] loss: 0.084\n",
      "Accuracy of the network on the test images: 88.92 %\n",
      "[51] loss: 0.078\n",
      "Accuracy of the network on the test images: 88.95 %\n",
      "[52] loss: 0.077\n",
      "Accuracy of the network on the test images: 88.45 %\n",
      "[53] loss: 0.075\n",
      "Accuracy of the network on the test images: 88.77 %\n",
      "[54] loss: 0.076\n",
      "Accuracy of the network on the test images: 88.82 %\n",
      "[55] loss: 0.073\n",
      "Accuracy of the network on the test images: 88.69 %\n",
      "[56] loss: 0.071\n",
      "Accuracy of the network on the test images: 88.99 %\n",
      "[57] loss: 0.072\n",
      "Accuracy of the network on the test images: 88.91 %\n",
      "[58] loss: 0.068\n",
      "Accuracy of the network on the test images: 88.13 %\n",
      "[59] loss: 0.068\n",
      "Accuracy of the network on the test images: 88.91 %\n",
      "[60] loss: 0.071\n",
      "Accuracy of the network on the test images: 88.49 %\n",
      "[61] loss: 0.060\n",
      "Accuracy of the network on the test images: 88.87 %\n",
      "[62] loss: 0.059\n",
      "Accuracy of the network on the test images: 88.51 %\n",
      "[63] loss: 0.063\n",
      "Accuracy of the network on the test images: 88.89 %\n",
      "[64] loss: 0.060\n",
      "Accuracy of the network on the test images: 88.77 %\n",
      "[65] loss: 0.063\n",
      "Accuracy of the network on the test images: 88.52 %\n",
      "[66] loss: 0.059\n",
      "Accuracy of the network on the test images: 88.37 %\n",
      "[67] loss: 0.057\n",
      "Accuracy of the network on the test images: 88.56 %\n",
      "[68] loss: 0.058\n",
      "Accuracy of the network on the test images: 88.36 %\n",
      "[69] loss: 0.058\n",
      "Accuracy of the network on the test images: 88.73 %\n",
      "[70] loss: 0.055\n",
      "Accuracy of the network on the test images: 88.32 %\n",
      "[71] loss: 0.056\n",
      "Accuracy of the network on the test images: 88.46 %\n",
      "[72] loss: 0.058\n",
      "Accuracy of the network on the test images: 88.55 %\n",
      "[73] loss: 0.047\n",
      "Accuracy of the network on the test images: 88.58 %\n",
      "[74] loss: 0.052\n",
      "Accuracy of the network on the test images: 88.34 %\n",
      "[75] loss: 0.054\n",
      "Accuracy of the network on the test images: 88.46 %\n",
      "[76] loss: 0.048\n",
      "Accuracy of the network on the test images: 88.55 %\n",
      "[77] loss: 0.048\n",
      "Accuracy of the network on the test images: 88.50 %\n",
      "[78] loss: 0.051\n",
      "Accuracy of the network on the test images: 88.72 %\n",
      "[79] loss: 0.045\n",
      "Accuracy of the network on the test images: 88.23 %\n",
      "[80] loss: 0.049\n",
      "Accuracy of the network on the test images: 88.45 %\n",
      "[81] loss: 0.048\n",
      "Accuracy of the network on the test images: 88.02 %\n",
      "[82] loss: 0.051\n",
      "Accuracy of the network on the test images: 88.84 %\n",
      "[83] loss: 0.048\n",
      "Accuracy of the network on the test images: 88.61 %\n",
      "[84] loss: 0.046\n",
      "Accuracy of the network on the test images: 89.02 %\n",
      "[85] loss: 0.037\n",
      "Accuracy of the network on the test images: 88.64 %\n",
      "[86] loss: 0.052\n",
      "Accuracy of the network on the test images: 88.30 %\n",
      "[87] loss: 0.045\n",
      "Accuracy of the network on the test images: 88.37 %\n",
      "[88] loss: 0.037\n",
      "Accuracy of the network on the test images: 88.42 %\n",
      "[89] loss: 0.049\n",
      "Accuracy of the network on the test images: 88.16 %\n",
      "[90] loss: 0.043\n",
      "Accuracy of the network on the test images: 88.56 %\n",
      "[91] loss: 0.040\n",
      "Accuracy of the network on the test images: 88.03 %\n",
      "[92] loss: 0.040\n",
      "Accuracy of the network on the test images: 88.57 %\n",
      "[93] loss: 0.037\n",
      "Accuracy of the network on the test images: 88.13 %\n",
      "[94] loss: 0.041\n",
      "Accuracy of the network on the test images: 88.52 %\n",
      "[95] loss: 0.044\n",
      "Accuracy of the network on the test images: 88.39 %\n",
      "[96] loss: 0.036\n",
      "Accuracy of the network on the test images: 88.59 %\n",
      "[97] loss: 0.037\n",
      "Accuracy of the network on the test images: 88.66 %\n",
      "[98] loss: 0.043\n",
      "Accuracy of the network on the test images: 88.52 %\n",
      "[99] loss: 0.038\n",
      "Accuracy of the network on the test images: 88.70 %\n",
      "[100] loss: 0.042\n",
      "Accuracy of the network on the test images: 88.66 %\n",
      "[101] loss: 0.040\n",
      "Accuracy of the network on the test images: 88.49 %\n",
      "[102] loss: 0.026\n",
      "Accuracy of the network on the test images: 88.59 %\n",
      "[103] loss: 0.038\n",
      "Accuracy of the network on the test images: 88.71 %\n",
      "[104] loss: 0.043\n",
      "Accuracy of the network on the test images: 88.50 %\n",
      "[105] loss: 0.032\n",
      "Accuracy of the network on the test images: 88.04 %\n",
      "[106] loss: 0.043\n",
      "Accuracy of the network on the test images: 88.07 %\n",
      "[107] loss: 0.040\n",
      "Accuracy of the network on the test images: 87.71 %\n",
      "[108] loss: 0.034\n",
      "Accuracy of the network on the test images: 88.43 %\n",
      "[109] loss: 0.029\n",
      "Accuracy of the network on the test images: 88.25 %\n",
      "[110] loss: 0.037\n",
      "Accuracy of the network on the test images: 88.37 %\n",
      "[111] loss: 0.040\n",
      "Accuracy of the network on the test images: 88.41 %\n",
      "[112] loss: 0.031\n",
      "Accuracy of the network on the test images: 88.25 %\n",
      "[113] loss: 0.041\n",
      "Accuracy of the network on the test images: 88.57 %\n",
      "[114] loss: 0.036\n",
      "Accuracy of the network on the test images: 88.69 %\n",
      "[115] loss: 0.031\n",
      "Accuracy of the network on the test images: 88.42 %\n",
      "[116] loss: 0.036\n",
      "Accuracy of the network on the test images: 88.57 %\n",
      "[117] loss: 0.033\n",
      "Accuracy of the network on the test images: 88.31 %\n",
      "[118] loss: 0.033\n",
      "Accuracy of the network on the test images: 88.42 %\n",
      "[119] loss: 0.040\n",
      "Accuracy of the network on the test images: 87.76 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[120] loss: 0.043\n",
      "Accuracy of the network on the test images: 88.40 %\n",
      "[121] loss: 0.026\n",
      "Accuracy of the network on the test images: 88.36 %\n",
      "[122] loss: 0.039\n",
      "Accuracy of the network on the test images: 88.17 %\n",
      "[123] loss: 0.028\n",
      "Accuracy of the network on the test images: 88.48 %\n",
      "[124] loss: 0.031\n",
      "Accuracy of the network on the test images: 87.93 %\n",
      "[125] loss: 0.034\n",
      "Accuracy of the network on the test images: 88.34 %\n",
      "[126] loss: 0.040\n",
      "Accuracy of the network on the test images: 88.13 %\n",
      "[127] loss: 0.031\n",
      "Accuracy of the network on the test images: 88.64 %\n",
      "[128] loss: 0.028\n",
      "Accuracy of the network on the test images: 88.18 %\n",
      "[129] loss: 0.028\n",
      "Accuracy of the network on the test images: 88.00 %\n",
      "[130] loss: 0.034\n",
      "Accuracy of the network on the test images: 88.54 %\n",
      "[131] loss: 0.042\n",
      "Accuracy of the network on the test images: 87.97 %\n",
      "[132] loss: 0.027\n",
      "Accuracy of the network on the test images: 88.38 %\n",
      "[133] loss: 0.033\n",
      "Accuracy of the network on the test images: 87.89 %\n",
      "[134] loss: 0.027\n",
      "Accuracy of the network on the test images: 88.33 %\n",
      "[135] loss: 0.037\n",
      "Accuracy of the network on the test images: 88.29 %\n",
      "[136] loss: 0.026\n",
      "Accuracy of the network on the test images: 87.87 %\n",
      "[137] loss: 0.031\n",
      "Accuracy of the network on the test images: 87.93 %\n",
      "[138] loss: 0.032\n",
      "Accuracy of the network on the test images: 88.09 %\n",
      "[139] loss: 0.025\n",
      "Accuracy of the network on the test images: 88.01 %\n",
      "[140] loss: 0.034\n",
      "Accuracy of the network on the test images: 87.47 %\n",
      "[141] loss: 0.033\n",
      "Accuracy of the network on the test images: 87.38 %\n",
      "[142] loss: 0.028\n",
      "Accuracy of the network on the test images: 88.40 %\n",
      "[143] loss: 0.022\n",
      "Accuracy of the network on the test images: 87.99 %\n",
      "[144] loss: 0.038\n",
      "Accuracy of the network on the test images: 88.18 %\n",
      "[145] loss: 0.027\n",
      "Accuracy of the network on the test images: 88.53 %\n",
      "[146] loss: 0.034\n",
      "Accuracy of the network on the test images: 88.44 %\n",
      "[147] loss: 0.031\n",
      "Accuracy of the network on the test images: 88.15 %\n",
      "[148] loss: 0.028\n",
      "Accuracy of the network on the test images: 88.27 %\n",
      "[149] loss: 0.023\n",
      "Accuracy of the network on the test images: 88.23 %\n",
      "[150] loss: 0.035\n",
      "Accuracy of the network on the test images: 87.90 %\n"
     ]
    }
   ],
   "source": [
    "r = 0.2\n",
    "'''\n",
    "VFOGD_PF_02_Loss = []\n",
    "VFOGD_PF_02_Accuracy = []\n",
    "\n",
    "\n",
    "VFOAdam_PF_02_Loss = []\n",
    "VFOAdam_PF_02_Accuracy = []\n",
    "'''\n",
    "IFOAdam_PF_02_Loss = []\n",
    "IFOAdam_PF_02_Accuracy = []\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = Net()\n",
    "net.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer1 = torch.optim.SGD([{'params': net.conv1.parameters()},\n",
    "                              {'params': net.pool.parameters()},\n",
    "                              {'params': net.conv2.parameters()}], lr=0.001, momentum=0.9)\n",
    "'''\n",
    "optimizer2 = VFOSGD_PF([{'params': net.fc1.parameters()},\n",
    "                       {'params': net.fc2.parameters()},\n",
    "                       {'params': net.fc3.parameters()}],r=r,lr=0.001)\n",
    "\n",
    "'''\n",
    "optimizer2 = VFOAdam_PF([{'params': net.fc1.parameters()},\n",
    "                       {'params': net.fc2.parameters()},\n",
    "                       {'params': net.fc3.parameters()}],r=r,lr=0.001)\n",
    "\n",
    "# training\n",
    "for epoch in range(150):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        #optimizer1.zero_grad()\n",
    "        #optimizer2.zero_grad()\n",
    "        net.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer1.step()\n",
    "        optimizer2.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print('[%d] loss: %.3f' % (epoch + 1, running_loss / len(trainloader)))\n",
    "    #VFOGD_PF_02_Loss.append(running_loss / len(trainloader))\n",
    "    #IFOGD_PF_02_Loss.append(running_loss / len(trainloader))\n",
    "    #VFOAdam_PF_02_Loss.append(running_loss / len(trainloader))\n",
    "    IFOAdam_PF_02_Loss.append(running_loss / len(trainloader))\n",
    "\n",
    "    # estimate\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the test images: %.2f %%' % (\n",
    "        100 * correct / total))\n",
    "    #VFOGD_PF_02_Accuracy.append(correct / total)\n",
    "    VFOAdam_PF_02_Accuracy.append(correct / total)\n",
    "    net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1c3436df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "data = pd.DataFrame([VFOGD_PF_02_Loss,VFOGD_PF_04_Loss,VFOGD_PF_06_Loss,VFOGD_PF_08_Loss,VFOGD_PF_10_Loss,VFOGD_PF_12_Loss,VFOGD_PF_14_Loss],\n",
    "                    index=['VFOGD_PF_02_Loss','VFOGD_PF_04_Loss','VFOGD_PF_06_Loss','VFOGD_PF_08_Loss','VFOGD_PF_10_Loss','VFOGD_PF_12_Loss','VFOGD_PF_14_Loss'])\n",
    "data.to_csv('fashion_mnist_loss_accuracy/VFOGD_PF_Loss.csv')\n",
    "\n",
    "\n",
    "data = pd.DataFrame([IFOGD_PF_02_Loss,IFOGD_PF_04_Loss,IFOGD_PF_06_Loss,IFOGD_PF_08_Loss,IFOGD_PF_10_Loss,IFOGD_PF_12_Loss,IFOGD_PF_14_Loss,IFOGD_PF_16_Loss,IFOGD_PF_18_Loss],\n",
    "                    index=['IFOGD_PF_02_Loss','IFOGD_PF_04_Loss','IFOGD_PF_06_Loss','IFOGD_PF_08_Loss','IFOGD_PF_10_Loss','IFOGD_PF_12_Loss','IFOGD_PF_14_Loss','IFOGD_PF_16_Loss','IFOGD_PF_18_Loss'])\n",
    "data.to_csv('fashion_mnist_loss_accuracy/IFOGD_PF_Loss.csv')\n",
    "\n",
    "data = pd.DataFrame([VFOGD_PF_02_Accuracy,VFOGD_PF_04_Accuracy,VFOGD_PF_06_Accuracy,VFOGD_PF_08_Accuracy,VFOGD_PF_10_Accuracy,VFOGD_PF_12_Accuracy,VFOGD_PF_14_Accuracy],\n",
    "                    index=['VFOGD_PF_02_Accuracy','VFOGD_PF_04_Accuracy','VFOGD_PF_06_Accuracy','VFOGD_PF_08_Accuracy','VFOGD_PF_10_Accuracy','VFOGD_PF_12_Accuracy','VFOGD_PF_14_Accuracy'])\n",
    "data.to_csv('fashion_mnist_loss_accuracy/VFOGD_PF_Accuracy.csv')\n",
    "\n",
    "\n",
    "data = pd.DataFrame([IFOGD_PF_02_Accuracy,IFOGD_PF_04_Accuracy,IFOGD_PF_06_Accuracy,IFOGD_PF_08_Accuracy,IFOGD_PF_10_Accuracy,IFOGD_PF_12_Accuracy,IFOGD_PF_14_Accuracy,IFOGD_PF_16_Accuracy,IFOGD_PF_18_Accuracy],\n",
    "                    index=['IFOGD_PF_02_Accuracy','IFOGD_PF_04_Accuracy','IFOGD_PF_06_Accuracy','IFOGD_PF_08_Accuracy','IFOGD_PF_10_Accuracy','IFOGD_PF_12_Accuracy','IFOGD_PF_14_Accuracy','IFOGD_PF_16_Accuracy','IFOGD_PF_18_Accuracy'])\n",
    "data.to_csv('fashion_mnist_loss_accuracy/IFOGD_PF_Accuracy.csv')\n",
    "data = pd.DataFrame([VFOAdam_PF_02_Loss,VFOAdam_PF_04_Loss,VFOAdam_PF_06_Loss,VFOAdam_PF_08_Loss,VFOAdam_PF_10_Loss,VFOAdam_PF_12_Loss,VFOAdam_PF_14_Loss],\n",
    "                    index=['VFOAdam_PF_02_Loss','VFOAdam_PF_04_Loss','VFOAdam_PF_06_Loss','VFOAdam_PF_08_Loss','VFOAdam_PF_10_Loss','VFOAdam_PF_12_Loss','VFOAdam_PF_14_Loss'])\n",
    "data.to_csv('fashion_mnist_loss_accuracy/VFOAdam_PF_Loss.csv')\n",
    "'''\n",
    "data = pd.DataFrame([VFOAdam_PF_02_Accuracy,VFOAdam_PF_04_Accuracy,VFOAdam_PF_06_Accuracy,VFOAdam_PF_08_Accuracy,VFOAdam_PF_10_Accuracy,VFOAdam_PF_12_Accuracy,VFOAdam_PF_14_Accuracy],\n",
    "                    index=['VFOAdam_PF_02_Accuracy','VFOAdam_PF_04_Accuracy','VFOAdam_PF_06_Accuracy','VFOAdam_PF_08_Accuracy','VFOAdam_PF_10_Accuracy','VFOAdam_PF_12_Accuracy','VFOAdam_PF_14_Accuracy'])\n",
    "data.to_csv('fashion_mnist_loss_accuracy/VFOAdam_PF_Accuracy.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
